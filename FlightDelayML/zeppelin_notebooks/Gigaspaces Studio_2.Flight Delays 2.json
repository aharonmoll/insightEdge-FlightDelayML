{"paragraphs":[{"text":"%md\n##  ==  [Getting Started - Part 1 or 2] (#/notebook/INSIGHTEDGE-GETTING-STARTED) ==\n##  ==> Getting Started - Part 2 or 2 <==","user":"anonymous","dateUpdated":"2020-05-05T20:36:40+0300","config":{"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h2>== <a href=\"#/notebook/INSIGHTEDGE-GETTING-STARTED\">Getting Started - Part 1 or 2</a> ==</h2>\n<h2>==&gt; Getting Started - Part 2 or 2 &lt;==</h2>\n</div>"}]},"apps":[],"jobName":"paragraph_1588700200413_2087876528","id":"20191202-140427_1777828485","dateCreated":"2020-05-05T20:36:40+0300","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:22970"},{"text":"%md\n\n### Enriching the Flight Data\n\nAfter the data has been prepared, the next step is to fetch the daily weather data for the required time period and merge it with the flight delay data. (We have this data stored in a CSV file. If you don't have access to the data for some reason, you can download it from <https://insightedge-gettingstarted.s3.amazonaws.com/weather2017_8.csv.zip>.) \n\n**DistributedTasks** - To merge the weather data with the flight delay data we use the DistributedTasks capability, which lets us define code that executes in a distributed fashion over the in-memory data. This feature can also leverage the performance gains from the co-location of the logic/process and the data in the same Space.\n\nAfter the data is merged, we query it to verify that the new fields were added.\n","user":"anonymous","dateUpdated":"2020-05-05T20:36:40+0300","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h3>Enriching the Flight Data</h3>\n<p>After the data has been prepared, the next step is to fetch the daily weather data for the required time period and merge it with the flight delay data. (We have this data stored in a CSV file. If you don&rsquo;t have access to the data for some reason, you can download it from <a href=\"https://insightedge-gettingstarted.s3.amazonaws.com/weather2017_8.csv.zip\">https://insightedge-gettingstarted.s3.amazonaws.com/weather2017_8.csv.zip</a>.) </p>\n<p><strong>DistributedTasks</strong> - To merge the weather data with the flight delay data we use the DistributedTasks capability, which lets us define code that executes in a distributed fashion over the in-memory data. This feature can also leverage the performance gains from the co-location of the logic/process and the data in the same Space.</p>\n<p>After the data is merged, we query it to verify that the new fields were added.</p>\n</div>"}]},"apps":[],"jobName":"paragraph_1588700200414_-792158307","id":"20190826-022957_1704419410","dateCreated":"2020-05-05T20:36:40+0300","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:22971"},{"title":"Restart interpreter before using '%dep' & '%define'","text":"%sh\n# wget --method=PUT -O /dev/null http://localhost:9090/api/interpreter/setting/restart/spark\n\ncurl -i -X PUT  -O /dev/null http://localhost:9090/api/interpreter/setting/restart/spark\n\n","user":"anonymous","dateUpdated":"2020-05-05T20:36:40+0300","config":{"editorSetting":{"language":"sh","editOnDblClick":false,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/sh","fontSize":9,"editorHide":false,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"curl: (3) <url> malformed\n  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n                                 Dload  Upload   Total   Spent    Left  Speed\n\r  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\r  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\r  0     0    0     0    0     0      0      0 --:--:--  0:00:01 --:--:--     0\r  0     0    0     0    0     0      0      0 --:--:--  0:00:02 --:--:--     0\r100  3925  100  3925    0     0   1516      0  0:00:02  0:00:02 --:--:--  1515\nHTTP/1.1 200 OK\r\nDate: Sunday, May 3, 2020 10:15:10 AM UTC\r\nAccess-Control-Allow-Credentials: true\r\nAccess-Control-Allow-Headers: authorization,Content-Type\r\nAccess-Control-Allow-Methods: POST, GET, OPTIONS, PUT, HEAD, DELETE\r\nX-FRAME-OPTIONS: SAMEORIGIN\r\nX-XSS-Protection: 1\r\nContent-Type: application/json\r\nContent-Length: 3925\r\nServer: Jetty(9.4.14.v20181114)\r\n\r\n{\"status\":\"OK\",\"message\":\"\",\"body\":{\"id\":\"spark\",\"name\":\"spark\",\"group\":\"spark\",\"properties\":{\"spark.executor.memory\":{\"name\":\"spark.executor.memory\",\"value\":\"\",\"type\":\"string\"},\"zeppelin.spark.sql.interpolation\":{\"name\":\"zeppelin.spark.sql.interpolation\",\"value\":false,\"type\":\"checkbox\"},\"zeppelin.spark.concurrentSQL\":{\"name\":\"zeppelin.spark.concurrentSQL\",\"value\":false,\"type\":\"checkbox\"},\"zeppelin.R.knitr\":{\"name\":\"zeppelin.R.knitr\",\"value\":true,\"type\":\"checkbox\"},\"zeppelin.R.cmd\":{\"name\":\"zeppelin.R.cmd\",\"value\":\"R\",\"type\":\"string\"},\"spark.app.name\":{\"name\":\"spark.app.name\",\"value\":\"Zeppelin\",\"type\":\"string\"},\"zeppelin.R.image.width\":{\"name\":\"zeppelin.R.image.width\",\"value\":\"100%\",\"type\":\"number\"},\"zeppelin.spark.importImplicit\":{\"name\":\"zeppelin.spark.importImplicit\",\"value\":true,\"type\":\"checkbox\"},\"zeppelin.dep.additionalRemoteRepository\":{\"name\":\"zeppelin.dep.additionalRemoteRepository\",\"value\":\"spark-packages,http://dl.bintray.com/spark-packages/maven,false;\",\"type\":\"textarea\"},\"zeppelin.spark.maxResult\":{\"name\":\"zeppelin.spark.maxResult\",\"value\":\"1000\",\"type\":\"number\"},\"master\":{\"name\":\"master\",\"value\":\"local[*]\",\"type\":\"string\"},\"zeppelin.pyspark.python\":{\"name\":\"zeppelin.pyspark.python\",\"value\":\"python\",\"type\":\"string\"},\"args\":{\"name\":\"args\",\"value\":\"\",\"type\":\"textarea\"},\"zeppelin.spark.enableSupportedVersionCheck\":{\"name\":\"zeppelin.spark.enableSupportedVersionCheck\",\"value\":true,\"type\":\"checkbox\"},\"zeppelin.spark.useNew\":{\"name\":\"zeppelin.spark.useNew\",\"value\":false,\"type\":\"checkbox\"},\"zeppelin.dep.localrepo\":{\"name\":\"zeppelin.dep.localrepo\",\"value\":\"local-repo\",\"type\":\"string\"},\"zeppelin.pyspark.useIPython\":{\"name\":\"zeppelin.pyspark.useIPython\",\"value\":true,\"type\":\"checkbox\"},\"zeppelin.spark.sql.stacktrace\":{\"name\":\"zeppelin.spark.sql.stacktrace\",\"value\":false,\"type\":\"checkbox\"},\"zeppelin.spark.useHiveContext\":{\"name\":\"zeppelin.spark.useHiveContext\",\"value\":true,\"type\":\"checkbox\"},\"zeppelin.spark.uiWebUrl\":{\"name\":\"zeppelin.spark.uiWebUrl\",\"value\":\"\",\"type\":\"string\"},\"zeppelin.R.render.options\":{\"name\":\"zeppelin.R.render.options\",\"value\":\"out.format \\u003d \\u0027html\\u0027, comment \\u003d NA, echo \\u003d FALSE, results \\u003d \\u0027asis\\u0027, message \\u003d F, warning \\u003d F, fig.retina \\u003d 2\",\"type\":\"textarea\"},\"zeppelin.spark.printREPLOutput\":{\"name\":\"zeppelin.spark.printREPLOutput\",\"value\":true,\"type\":\"checkbox\"},\"spark.cores.max\":{\"name\":\"spark.cores.max\",\"value\":\"\",\"type\":\"number\"}},\"status\":\"READY\",\"interpreterGroup\":[{\"name\":\"spark\",\"class\":\"org.apache.zeppelin.spark.SparkInterpreter\",\"defaultInterpreter\":true,\"editor\":{\"language\":\"scala\",\"editOnDblClick\":false,\"completionKey\":\"TAB\",\"completionSupport\":true}},{\"name\":\"sql\",\"class\":\"org.apache.zeppelin.spark.SparkSqlInterpreter\",\"defaultInterpreter\":false,\"editor\":{\"language\":\"sql\",\"editOnDblClick\":false,\"completionKey\":\"TAB\",\"completionSupport\":true}},{\"name\":\"dep\",\"class\":\"org.apache.zeppelin.spark.DepInterpreter\",\"defaultInterpreter\":false,\"editor\":{\"language\":\"scala\",\"editOnDblClick\":false,\"completionKey\":\"TAB\",\"completionSupport\":true}},{\"name\":\"pyspark\",\"class\":\"org.apache.zeppelin.spark.PySparkInterpreter\",\"defaultInterpreter\":false,\"editor\":{\"language\":\"python\",\"editOnDblClick\":false,\"completionKey\":\"TAB\",\"completionSupport\":true}},{\"name\":\"ipyspark\",\"class\":\"org.apache.zeppelin.spark.IPySparkInterpreter\",\"defaultInterpreter\":false,\"editor\":{\"language\":\"python\",\"editOnDblClick\":false,\"completionSupport\":true}},{\"name\":\"r\",\"class\":\"org.apache.zeppelin.spark.SparkRInterpreter\",\"defaultInterpreter\":false,\"editor\":{\"language\":\"r\",\"editOnDblClick\":false,\"completionSupport\":false}},{\"name\":\"define\",\"class\":\"org.apache.zeppelin.insightedge.CompilingInterpreter\",\"defaultInterpreter\":false,\"editor\":{\"language\":\"scala\",\"editOnDblClick\":false}}],\"dependencies\":[],\"option\":{\"remote\":true,\"port\":-1,\"isExistingProcess\":false,\"setPermission\":false,\"owners\":[],\"isUserImpersonate\":false}}}"}]},"apps":[],"jobName":"paragraph_1588700200414_-2006650811","id":"20191023-083057_1327164381","dateCreated":"2020-05-05T20:36:40+0300","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:22972"},{"title":"Load external libraries","text":"%dep\n\nz.load(\"org.apache.spark:spark-streaming-kafka-0-8_2.11:2.2.0\")\nz.load(\"com.google.code.gson:gson:2.8.5\")\n","user":"anonymous","dateUpdated":"2020-05-05T20:36:40+0300","config":{"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"res0: org.apache.zeppelin.dep.Dependency = org.apache.zeppelin.dep.Dependency@a25858d\n"}]},"apps":[],"jobName":"paragraph_1588700200414_341256539","id":"20190925-105649_2122430845","dateCreated":"2020-05-05T20:36:40+0300","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:22973"},{"title":"Re-introduce the data model Case Class that was defined in the previous notebook","text":"%define\npackage model.v1\n\nimport com.gigaspaces.metadata._\nimport com.gigaspaces.metadata.index.SpaceIndexType;\nimport java.lang\nimport scala.beans.{BeanProperty}\nimport org.insightedge.scala.annotation._\nimport org.insightedge.spark.implicits.all._\n\n\n//Describe the data as Scala Case Class\n\ncase class FlightDelaysWithWeather(\n  @BeanProperty \n  @SpaceId\n  var id: String,\n  @BeanProperty \n  @SpaceIndex\n  var carrier: String,\n  @BeanProperty \n  @SpaceIndex\n  var flight_number: String,\n  @SpaceIndex\n  @BeanProperty \n  var year: Integer,\n  @BeanProperty \n  var month: String,\n  @BeanProperty \n  var dayofMonth: String,\n  @BeanProperty \n  var dayOfWeek: String,\n  @BeanProperty \n  var crsDepTime: String,\n  @SpaceIndex\n  @BeanProperty \n  var depDelay15: java.lang.Double,\n  @BeanProperty \n  var depDelay: java.lang.Double,\n  @SpaceIndex\n  @BeanProperty \n  var origin: String,\n  @BeanProperty \n  var dest: String,\n  @BeanProperty \n  var awnd: String,\n  @BeanProperty \n  var prcp: String,\n  @BeanProperty \n  var snow: String,\n  @BeanProperty \n  var tmax: String,\n  @BeanProperty \n  var tmin: String,\n  @BeanProperty \n  var cancelled: String,\n  @BeanProperty\n  var date: Integer,\n  @BeanProperty \n  var prediction: String ) {\n  def this() = this(null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null)\n  def generate_id() = {id = \"%04d:%s:%s:%s:%s:%s\".format(year, month, dayofMonth, dayOfWeek, crsDepTime, flight_number)}\n}\n","user":"anonymous","dateUpdated":"2020-05-05T20:36:40+0300","config":{"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"res1: org.apache.zeppelin.dep.Dependency = org.apache.zeppelin.dep.Dependency@500b2bf\n"}]},"apps":[],"jobName":"paragraph_1588700200414_1573580286","id":"20190925-105731_273091578","dateCreated":"2020-05-05T20:36:40+0300","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:22974"},{"title":"Enrich the FlightDelay data with weather data","text":"%spark\nimport org.apache.spark.SparkContext._\nimport org.apache.spark.SparkFiles\nimport spark.implicits._\n\n\nspark.sparkContext.addFile(\"http://amoll.s3-eu-west-1.amazonaws.com/Services/weather2017_8.csv\")\nval weatherDataFrame = spark.read.option(\"header\", \"true\").option(\"inferschema\", \"true\").csv(SparkFiles.get(\"weather2017_8.csv\"))\n\n\n//Add task for merging the weather and flight delays","user":"anonymous","dateUpdated":"2020-05-05T20:37:57+0300","config":{"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"editorHide":false,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"import org.apache.spark.SparkContext._\nimport spark.implicits._\nweatherDataFrame: org.apache.spark.sql.DataFrame = [Date: int, Station: string ... 5 more fields]\n"}]},"apps":[],"jobName":"paragraph_1588700200414_-405585061","id":"20190818-160913_12361618","dateCreated":"2020-05-05T20:36:40+0300","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:22975"},{"text":"%spark\n\nimport org.insightedge.spark.implicits.all._\nimport org.insightedge.spark.context.InsightEdgeConfig\n\n//Change space name here if not working with default\n//val ieConfig = new InsightEdgeConfig(System.getenv(\"INSIGHTEDGE_SPACE_NAME\"))\nval ieConfig = new InsightEdgeConfig(\"flights_space\")\nsc.initializeInsightEdgeContext(ieConfig)\n","user":"anonymous","dateUpdated":"2020-05-05T20:36:40+0300","config":{"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"import org.insightedge.spark.implicits.all._\nimport org.insightedge.spark.context.InsightEdgeConfig\nieConfig: org.insightedge.spark.context.InsightEdgeConfig = InsightEdgeConfig(flights_space,None,None)\nres0: org.apache.spark.SparkContext = org.apache.spark.SparkContext@7e028b2\n"}]},"apps":[],"jobName":"paragraph_1588700200414_410670594","id":"20190925-133356_683462357","dateCreated":"2020-05-05T20:36:40+0300","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:22976"},{"title":"Register the additional \"Weather\" Type with the data grid","text":"import model.v1._\nimport com.gigaspaces.metadata._\nimport com.gigaspaces.metadata.index.SpaceIndexType;\nimport java.lang\nimport scala.beans.{BeanProperty}\nimport org.insightedge.scala.annotation._\nimport org.insightedge.spark.implicits.all._\n\n\nval typeDescriptor: SpaceTypeDescriptor = new SpaceTypeDescriptorBuilder(\"Weather\").idProperty(\"id\", true)\n                .addFixedProperty(\"Date\", \"java.lang.Integer\")\n                .addFixedProperty(\"Station\", \"java.lang.String\")\n                .addPropertyIndex(\"Date\", SpaceIndexType.EQUAL)\n                .addPropertyIndex(\"Station\", SpaceIndexType.EQUAL)\n                .routingProperty(\"Date\")\n                .create();\n                \n        // Register type:\nsc.grid.getTypeManager().registerTypeDescriptor(typeDescriptor)\nsc.grid.getTypeManager.registerTypeDescriptor(classOf[FlightDelaysWithWeather])\n","user":"anonymous","dateUpdated":"2020-05-05T20:36:40+0300","config":{"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"import model.v1._\nimport com.gigaspaces.metadata._\nimport com.gigaspaces.metadata.index.SpaceIndexType\nimport java.lang\nimport scala.beans.BeanProperty\nimport org.insightedge.scala.annotation._\nimport org.insightedge.spark.implicits.all._\ntypeDescriptor: com.gigaspaces.metadata.SpaceTypeDescriptor = TypeDesc[typeName=Weather, checksum=-448861464, codebase=null, superTypesNames=[Weather, java.lang.Object], supportsDynamicProperties=true, supportsOptimisticLocking=false, systemType=false, replicatable=true, blobstoreEnabled=true, storageType=OBJECT, fifoSupport=OFF, idPropertyName=id, idAutoGenerate=true, routingPropertyName=Date, fifoGroupingPropertyName=null, sequenceNumberPropertyName=null, objectClass=, documentWrapperClass=com.gigaspaces.document.SpaceDocument, fixedProperties=[Property[name=Date, type=java.lang.Integer], Property[name=Station, type=java.lang.String], Property[name=id, type=java.lang.String]], indexes=[SpaceIndex[name=Station, type=EQUAL, unique=false], SpaceIndex[name=Date, type=EQUAL, unique=false]]..."}]},"apps":[],"jobName":"paragraph_1588700200414_1354526079","id":"20190827-234813_998795403","dateCreated":"2020-05-05T20:36:40+0300","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:22977"},{"title":"Write the weather data to memory","text":"%spark\nimport org.apache.spark.sql.SaveMode\n\nsc.grid.clear(\"Weather\")\nweatherDataFrame.write.mode(SaveMode.Overwrite).grid(\"Weather\")","user":"anonymous","dateUpdated":"2020-05-05T20:36:40+0300","config":{"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"import org.apache.spark.sql.SaveMode\n"}]},"apps":[],"jobName":"paragraph_1588700200415_-2146177819","id":"20190827-235037_392240904","dateCreated":"2020-05-05T20:36:40+0300","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:22978"},{"text":"%md\n\n## Merge the weather and flight delays data together\n##### In the previous notebook we wrote the Flight Delays data to the memory grid\n##### In the notebook we wrote weather data for the same time period to the memory grid\n##### in the next paragraph, we define a distributed task that we will excute on the memory grid, \n##### this task will be sent to all the grid partitions and will execute the code below which will merge the weather data to the Flight Delays objects.\n","user":"anonymous","dateUpdated":"2020-05-05T20:36:40+0300","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h2>Merge the weather and flight delays data together</h2>\n<h5>In the previous notebook we wrote the Flight Delays data to the memory grid</h5>\n<h5>In the notebook we wrote weather data for the same time period to the memory grid</h5>\n<h5>in the next paragraph, we define a distributed task that we will excute on the memory grid,</h5>\n<h5>this task will be sent to all the grid partitions and will execute the code below which will merge the weather data to the Flight Delays objects.</h5>\n</div>"}]},"apps":[],"jobName":"paragraph_1588700200415_-18964935","id":"20191031-095618_1420923713","dateCreated":"2020-05-05T20:36:40+0300","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:22979"},{"title":"Define a task to enrich the flights delay records with relevant weather metrics","text":"%spark\nimport  model.v1._\nimport com.gigaspaces.async.AsyncResult\nimport org.openspaces.core.executor.DistributedTask\nimport org.insightedge.scala.annotation._\nimport scala.collection.JavaConversions._\nimport org.slf4j.{Logger, LoggerFactory}\nimport org.openspaces.core.GigaSpace\nimport org.openspaces.core.executor.TaskGigaSpace\nimport scala.beans.{BeanProperty}\nimport com.gigaspaces.document.SpaceDocument\nimport scala.collection.mutable.ListBuffer\nimport com.j_spaces.core.client.SQLQuery\n\n\nclass MergeTask extends DistributedTask[java.lang.Integer, java.lang.Integer] {\n  import scala.collection.JavaConversions._\n  private val logger = LoggerFactory.getLogger(classOf[MergeTask])\n  @TaskGigaSpace @transient private val gs: GigaSpace = null\n\noverride def execute(): Integer = {\n    if(gs != null) {\n      val clusteredProxy = gs.getClustered()\n      logger.info(\"execute returned from: \" + gs.getSpaceName)\n        val template =new SQLQuery[FlightDelaysWithWeather](classOf[FlightDelaysWithWeather], \"tmin is null\")\n        val weatherTemplate =new SpaceDocument(\"Weather\");\n        var writtenCount:Integer = 0\n        var retArray:Array[FlightDelaysWithWeather] = null\n        logger.info(\"Created template\")\n        try {\n            while ( {retArray = gs.takeMultiple(template, 1000);retArray  != null && retArray.length > 0}) {\n                var writeCollection = new ListBuffer[FlightDelaysWithWeather]\n                for (rec <- retArray) {\n                  val dateField:Int = (\"%d%02d%02d\".format(rec.year.toInt, rec.month.toInt, rec.dayofMonth.toInt)).toInt\n                  val origin:String =  rec.origin\n                  weatherTemplate.setProperty(\"Date\", dateField)\n                  weatherTemplate.setProperty(\"Station\", origin)\n                  val weather = clusteredProxy.read(weatherTemplate)\n                  if (weather != null) {\n                    rec.awnd = \"\" + weather.getProperty(\"AWND\")\n                    rec.prcp = \"\" + weather.getProperty(\"PRCP\")\n                    rec.snow = \"\" + weather.getProperty(\"SNOW\")\n                    rec.tmin = \"\" + weather.getProperty(\"TMIN\")\n                    rec.tmax = \"\" + weather.getProperty(\"TMAX\")\n                    rec.date =  dateField\n                    writeCollection += rec\n                  }\n                }\n                if(writeCollection.length > 0) {\n                    gs.writeMultiple(writeCollection.toArray)\n                } \n                writtenCount += writeCollection.length\n            }\n        } catch {\n            case e: Exception => logger.warn(e.getMessage, e)\n        }\n      logger.info(\"Finished task \" + writtenCount)\n\n      return writtenCount\n    } else {\n      logger.info(\"gs Proxy not available\")\n        return -1\n        \n    }\n  }\n  override def reduce(results: java.util.List[AsyncResult[Integer]]): java.lang.Integer = {\n    logger.info(\"In Reduce\")\n    return results.map(_.getResult().intValue()).sum\n  }}\n","user":"anonymous","dateUpdated":"2020-05-05T20:36:40+0300","config":{"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"import model.v1._\nimport com.gigaspaces.async.AsyncResult\nimport org.openspaces.core.executor.DistributedTask\nimport org.insightedge.scala.annotation._\nimport scala.collection.JavaConversions._\nimport org.slf4j.{Logger, LoggerFactory}\nimport org.openspaces.core.GigaSpace\nimport org.openspaces.core.executor.TaskGigaSpace\nimport scala.beans.BeanProperty\nimport com.gigaspaces.document.SpaceDocument\nimport scala.collection.mutable.ListBuffer\nimport com.j_spaces.core.client.SQLQuery\ndefined class MergeTask\n"}]},"apps":[],"jobName":"paragraph_1588700200415_1157042366","id":"20190925-085011_609572142","dateCreated":"2020-05-05T20:36:40+0300","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:22980"},{"title":"Execute the distributed task and get the enriched data as a Spark dataframe","text":"%spark\nimport com.gigaspaces.async.AsyncFuture;\nimport org.insightedge.spark.implicits.all._\n\nval future:AsyncFuture[Integer] = sc.grid.execute(new MergeTask())\nval result = future.get()\n\n","user":"anonymous","dateUpdated":"2020-05-05T20:36:40+0300","config":{"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"import com.gigaspaces.async.AsyncFuture\nimport org.insightedge.spark.implicits.all._\nfuture: com.gigaspaces.async.AsyncFuture[Integer] = org.openspaces.core.transaction.internal.InternalAsyncFuture@74a47d3e\nresult: Integer = 525155\n"}]},"apps":[],"jobName":"paragraph_1588700200415_-1128507000","id":"20190831-224510_2052488220","dateCreated":"2020-05-05T20:36:40+0300","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:22981"},{"title":"Review the enriched data","text":"%insightedge_jdbc\n\nselect carrier , origin, dest, depDelay, awnd, prcp, snow, tmin, tmax   from FlightDelaysWithWeather where awnd is not null limit 20\n","user":"anonymous","dateUpdated":"2020-05-05T20:36:40+0300","config":{"editorSetting":{"language":"sql","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/sql","fontSize":9,"editorHide":false,"title":true,"results":{"0":{"graph":{"mode":"table","height":300,"optionOpen":false,"setting":{"table":{"tableGridState":{},"tableColumnTypeState":{"names":{"carrier":"string","origin":"string","dest":"string","depDelay":"string","awnd":"string","prcp":"string","snow":"string","tmin":"string","tmax":"string"},"updated":false},"tableOptionSpecHash":"[{\"name\":\"useFilter\",\"valueType\":\"boolean\",\"defaultValue\":false,\"widget\":\"checkbox\",\"description\":\"Enable filter for columns\"},{\"name\":\"showPagination\",\"valueType\":\"boolean\",\"defaultValue\":false,\"widget\":\"checkbox\",\"description\":\"Enable pagination for better navigation\"},{\"name\":\"showAggregationFooter\",\"valueType\":\"boolean\",\"defaultValue\":false,\"widget\":\"checkbox\",\"description\":\"Enable a footer for displaying aggregated values\"}]","tableOptionValue":{"useFilter":false,"showPagination":false,"showAggregationFooter":false},"updated":false,"initialized":false}},"commonSetting":{}}}},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TABLE","data":"carrier\torigin\tdest\tdepDelay\tawnd\tprcp\tsnow\ttmin\ttmax\nUA\tDEN\tCID\t10.0\t55\t0\t0\t133\t344\nUA\tDEN\tOMA\t7.0\t55\t0\t0\t133\t344\nUA\tDEN\tSEA\t-1.0\t51\t0\t0\t67\t244\nUA\tDEN\tSFO\t4.0\t51\t0\t0\t67\t244\nUA\tORD\tMCO\t2.0\t35\t0\t0\t106\t217\nUA\tDEN\tSFO\t41.0\t55\t0\t0\t133\t344\nUA\tSFO\tORD\t-7.0\t34\t0\t0\t156\t283\nUA\tDEN\tRIC\t-9.0\t55\t0\t0\t133\t344\nUA\tDEN\tSNA\t-3.0\t46\t0\t0\t89\t294\nUA\tSFO\tSAN\t-8.0\t93\t0\t0\t106\t178\nF9\tDEN\tDCA\t-1.0\t38\t0\t0\t-60\t111\nOO\tSFO\tPSP\t-3.0\t69\t13\t0\t78\t122\nUA\tDEN\tSMF\t-10.0\t39\t0\t0\t144\t322\nUA\tDEN\tSAN\t-5.0\t46\t0\t0\t94\t278\nUA\tDEN\tIAH\t1.0\t62\t0\t0\t56\t256\nUA\tORD\tEWR\t-2.0\t41\t0\t0\t94\t183\nOO\tORD\tMKG\t-4.0\t28\t28\t0\t-38\t44\nOO\tORD\tMKE\t-4.0\t45\t0\t0\t-71\t39\nUA\tSFO\tDCA\t-4.0\t74\t0\t0\t156\t228\nUA\tDEN\tORD\t-3.0\t38\t5\t0\t78\t233\n"}]},"apps":[],"jobName":"paragraph_1588700200415_-1354652536","id":"20190818-171934_1385212060","dateCreated":"2020-05-05T20:36:40+0300","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:22982"},{"text":"%md\n\n### Preparing Feature Vectors\n\nIn the last stage of the data processing, we use the merged data to prepare feature vectors for all the fields we want to fit in our model, and label each vector with the resulting delay. nAs mentioned earlier, a positive number is the delay (in minutes) while a negative number indicates a flight that was early.\n","user":"anonymous","dateUpdated":"2020-05-05T20:36:40+0300","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h3>Preparing Feature Vectors</h3>\n<p>In the last stage of the data processing, we use the merged data to prepare feature vectors for all the fields we want to fit in our model, and label each vector with the resulting delay. nAs mentioned earlier, a positive number is the delay (in minutes) while a negative number indicates a flight that was early.</p>\n</div>"}]},"apps":[],"jobName":"paragraph_1588700200415_1283962106","id":"20190826-023258_963848778","dateCreated":"2020-05-05T20:36:40+0300","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:22983"},{"title":"Prepare the feature vector for the ML model","text":"%spark\nimport spark.implicits._\nimport org.apache.spark.rdd.RDD\nimport org.apache.spark.sql.Dataset\nimport org.apache.spark.mllib.regression.LabeledPoint\nimport org.apache.spark.mllib.linalg.Vectors\nimport org.apache.spark.mllib.feature.StandardScaler\nimport org.insightedge.scala.annotation._\nimport scala.beans.{BeanProperty}\n\n\ndef parseData(vals: Array[Double]): LabeledPoint = {\n   LabeledPoint(vals(0), Vectors.dense(vals.drop(1)))\n}\n\ndef prepareFeaturesLabeledPoint(_flightDelayswithWeatherDataSet: Dataset[FlightDelaysWithWeather]): RDD[LabeledPoint] = {\n    val featuresVectors = _flightDelayswithWeatherDataSet.map((o: FlightDelaysWithWeather) => Array(o.depDelay15.doubleValue(),  o.month.toDouble, o.dayOfWeek.toDouble,\n        (\"%04d\".format(o.crsDepTime.toInt).take(2)).toDouble, o.awnd.toDouble, o.prcp.toDouble, o.tmax.toDouble, o.tmin.toDouble))    \n     featuresVectors.rdd.map(parseData)\n} \n\nval FlightDelaysWithWeatherDataframe =  spark.read.grid[FlightDelaysWithWeather].as[FlightDelaysWithWeather]\n\nval traningData = prepareFeaturesLabeledPoint(FlightDelaysWithWeatherDataframe.filter(\"Year = 2017\"))\nval validationData = prepareFeaturesLabeledPoint(FlightDelaysWithWeatherDataframe.filter(\"Year = 2018\"))\n\n\n","user":"anonymous","dateUpdated":"2020-05-05T20:36:40+0300","config":{"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"editorHide":false,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"import spark.implicits._\nimport org.apache.spark.rdd.RDD\nimport org.apache.spark.sql.Dataset\nimport org.apache.spark.mllib.regression.LabeledPoint\nimport org.apache.spark.mllib.linalg.Vectors\nimport org.apache.spark.mllib.feature.StandardScaler\nimport org.insightedge.scala.annotation._\nimport scala.beans.BeanProperty\nparseData: (vals: Array[Double])org.apache.spark.mllib.regression.LabeledPoint\nprepareFeaturesLabeledPoint: (_flightDelayswithWeatherDataSet: org.apache.spark.sql.Dataset[model.v1.FlightDelaysWithWeather])org.apache.spark.rdd.RDD[org.apache.spark.mllib.regression.LabeledPoint]\nFlightDelaysWithWeatherDataframe: org.apache.spark.sql.Dataset[model.v1.FlightDelaysWithWeather] = [id: string, carrier: string ... 18 more fields]\ntraningData: org.apache.spark.rdd.RDD[org.apache.spark.mllib.regression.LabeledPoint] = MapPartitionsRDD[22] at map at <console>:88\nvalidationData: org.apache.spark.rdd.RDD[org.apache.spark.mllib.regression.LabeledPoint] = MapPartitionsRDD[30] at map at <console>:88\n"}]},"apps":[],"jobName":"paragraph_1588700200415_30185213","id":"20190819-134542_2030099805","dateCreated":"2020-05-05T20:36:40+0300","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:22984"},{"text":"%md\n\n### Training the ML Model\n\nWe are using the Random Forest model (forest of decision trees) with the Classification strategy. The 2017 data, which we prepared before, will be used to train the model.  The result is a fitted or trained model.\n\nAfter we train the model, we'll evalute it using the helper `eval_metrics` and `Metrics` class to rate each prediction as follows:\n\n* TP - True Positive\n* TN - True Negative\n* FP - False Positive\n* FN - False Negative \n\nWe can then sum it to evalute the model's accuracy.\n\nAfter the training with the 2017 data, we'll run the model with the 2018 data and decide if the accuracy satisfies our requirements.\n\n","user":"anonymous","dateUpdated":"2020-05-05T20:36:40+0300","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h3>Training the ML Model</h3>\n<p>We are using the Random Forest model (forest of decision trees) with the Classification strategy. The 2017 data, which we prepared before, will be used to train the model. The result is a fitted or trained model.</p>\n<p>After we train the model, we&rsquo;ll evalute it using the helper <code>eval_metrics</code> and <code>Metrics</code> class to rate each prediction as follows:</p>\n<ul>\n  <li>TP - True Positive</li>\n  <li>TN - True Negative</li>\n  <li>FP - False Positive</li>\n  <li>FN - False Negative</li>\n</ul>\n<p>We can then sum it to evalute the model&rsquo;s accuracy.</p>\n<p>After the training with the 2017 data, we&rsquo;ll run the model with the 2018 data and decide if the accuracy satisfies our requirements.</p>\n</div>"}]},"apps":[],"jobName":"paragraph_1588700200415_-799673841","id":"20190826-025537_806156844","dateCreated":"2020-05-05T20:36:40+0300","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:22985"},{"title":"Train the ML model and save it to the data grid","text":"%spark\n\nimport org.apache.spark.mllib.tree.RandomForest\nimport org.apache.spark.mllib.tree.configuration.Strategy\nimport org.insightedge.spark.implicits.all._\n\n\nval treeStrategy = Strategy.defaultStrategy(\"Classification\")\nval numTrees = 10 \nval featureSubsetStrategy = \"auto\" // Let the algorithm choose\nval predictFlightDelaysRFModel = RandomForest.trainClassifier(traningData, treeStrategy, numTrees, featureSubsetStrategy, seed = 123)\n//predictFlightDelaysRFModel.saveToGrid(sc, \"predictFlightDelaysRFModel\")","user":"anonymous","dateUpdated":"2020-05-05T20:36:40+0300","config":{"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"editorHide":false,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"import org.apache.spark.mllib.tree.RandomForest\nimport org.apache.spark.mllib.tree.configuration.Strategy\nimport org.insightedge.spark.implicits.all._\ntreeStrategy: org.apache.spark.mllib.tree.configuration.Strategy = org.apache.spark.mllib.tree.configuration.Strategy@57e9cad4\nnumTrees: Int = 10\nfeatureSubsetStrategy: String = auto\npredictFlightDelaysRFModel: org.apache.spark.mllib.tree.model.RandomForestModel =\nTreeEnsembleModel classifier with 10 trees\n"}]},"apps":[],"jobName":"paragraph_1588700200416_-232704866","id":"20190820-105429_26620422","dateCreated":"2020-05-05T20:36:40+0300","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:22986"},{"title":"Define the performance metrics","text":"%spark\nimport org.apache.spark.rdd._\nimport org.apache.spark.rdd.RDD\n\n// Function to compute evaluation metrics\ndef eval_metrics(labelsAndPreds: RDD[(Double, Double)]) : Tuple2[Array[Double], Array[Double]] = {\n    val tp = labelsAndPreds.filter(r => r._1==1 && r._2==1).count.toDouble\n    val tn = labelsAndPreds.filter(r => r._1==0 && r._2==0).count.toDouble\n    val fp = labelsAndPreds.filter(r => r._1==1 && r._2==0).count.toDouble\n    val fn = labelsAndPreds.filter(r => r._1==0 && r._2==1).count.toDouble\n    \n    val precision = tp / (tp+fp)\n    val recall = tp / (tp+fn)\n    val F_measure = 2*precision*recall / (precision+recall)\n    val accuracy = (tp+tn) / (tp+tn+fp+fn)\n    new Tuple2(Array(tp, tn, fp, fn), Array(precision, recall, F_measure, accuracy))\n}\n\n\nclass Metrics(labelsAndPreds: RDD[(Double, Double)]) extends java.io.Serializable {\n\n    private def filterCount(lftBnd:Int,rtBnd:Int):Double = labelsAndPreds\n                                                           .map(x => (x._1.toInt, x._2.toInt))\n                                                           .filter(_ == (lftBnd,rtBnd)).count()\n\n    lazy val tp = filterCount(1,1)  // true positives\n    lazy val tn = filterCount(0,0)  // true negatives\n    lazy val fp = filterCount(0,1)  // false positives\n    lazy val fn = filterCount(1,0)  // false negatives\n\n    lazy val precision = tp / (tp+fp)\n    lazy val recall = tp / (tp+fn)\n    lazy val F1 = 2*precision*recall / (precision+recall)\n    lazy val accuracy = (tp+tn) / (tp+tn+fp+fn)\n}","user":"anonymous","dateUpdated":"2020-05-05T20:36:40+0300","config":{"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"import org.apache.spark.rdd._\nimport org.apache.spark.rdd.RDD\neval_metrics: (labelsAndPreds: org.apache.spark.rdd.RDD[(Double, Double)])(Array[Double], Array[Double])\ndefined class Metrics\n"}]},"apps":[],"jobName":"paragraph_1588700200416_-962126526","id":"20190825-015117_1946128941","dateCreated":"2020-05-05T20:36:40+0300","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:22987"},{"title":"Evaluate the model on the test data","text":"%spark\nprintln(validationData)\nval predictionsResultsComparedToActual = validationData.map { point =>\n    val prediction = predictFlightDelaysRFModel.predict(point.features)\n    (point.label, prediction)\n}\npredictionsResultsComparedToActual.map(println)\nval modelMetrics = new Metrics(predictionsResultsComparedToActual)\nprintln(\"accuracy = %.2f\"\n        .format(modelMetrics.accuracy))\n","user":"anonymous","dateUpdated":"2020-05-05T20:36:40+0300","config":{"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"editorHide":false,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"MapPartitionsRDD[30] at map at <console>:88\npredictionsResultsComparedToActual: org.apache.spark.rdd.RDD[(Double, Double)] = MapPartitionsRDD[70] at map at <console>:96\nres6: org.apache.spark.rdd.RDD[Unit] = MapPartitionsRDD[71] at map at <console>:95\nmodelMetrics: Metrics = Metrics@96ec0b6\naccuracy = 0.79\n"}]},"apps":[],"jobName":"paragraph_1588700200416_233001494","id":"20190825-003059_736568661","dateCreated":"2020-05-05T20:36:40+0300","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:22988"},{"text":"%md\n\n### Stream flights data via Kafka to the memory grid\n\nIn the backgroud, feeder pushes flights data events to Kafka.\nIn the next paragraph Kafka streaming is use to write this data from Kafka to the memory grid.\nThe event prediction field is set to \"for_calc\" before a prediction is made.\n","user":"anonymous","dateUpdated":"2020-05-05T20:36:40+0300","config":{"tableHide":true,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":false,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h3>Stream flights data via Kafka to the memory grid</h3>\n<p>In the backgroud, feeder pushes flights data events to Kafka.<br/>In the next paragraph Kafka streaming is use to write this data from Kafka to the memory grid.<br/>The event prediction field is set to &ldquo;for_calc&rdquo; before a prediction is made.</p>\n</div>"}]},"apps":[],"jobName":"paragraph_1588700200416_-730264150","id":"20191111-123906_159111927","dateCreated":"2020-05-05T20:36:40+0300","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:22989"},{"title":"Use Spark Streaming for streaming flights data from Kafka and store it in the memory grid","text":"%spark\nimport _root_.kafka.serializer.StringDecoder\nimport model.v1._\nimport org.apache.spark.streaming._\nimport org.apache.spark.streaming.kafka._\nimport com.google.gson.Gson\n\n\n\n    val ssc = new StreamingContext(sc, Seconds(2))\n    val topics = \"flights\"\n    val topicsSet = topics.split(\",\").toSet\n   // val kafkaParams = Map[String, String](\"metadata.broker.list\" -> System.getenv(\"KAFKA_URL\"))\n    val kafkaParams = Map[String, String](\"metadata.broker.list\" -> \"kafka-0.service.consul:9092\")\n\n    val messages = KafkaUtils.createDirectStream[String, String, StringDecoder, StringDecoder](\n      ssc, kafkaParams, topicsSet)\n    messages.map { o =>\n        val gson = new Gson()\n        val fd = gson.fromJson( o._2, classOf[FlightDelaysWithWeather])\n        fd.generate_id()\n        fd.prediction = \"for_calc\"\n        fd\n   }.saveToGrid()\n\nssc.start\n\n","user":"anonymous","dateUpdated":"2020-05-05T20:36:40+0300","config":{"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"import _root_.kafka.serializer.StringDecoder\nimport model.v1._\nimport org.apache.spark.streaming._\nimport org.apache.spark.streaming.kafka._\nimport com.google.gson.Gson\nssc: org.apache.spark.streaming.StreamingContext = org.apache.spark.streaming.StreamingContext@49a8cee4\ntopics: String = flights\ntopicsSet: scala.collection.immutable.Set[String] = Set(flights)\nkafkaParams: scala.collection.immutable.Map[String,String] = Map(metadata.broker.list -> kafka-0.service.consul:9092)\nmessages: org.apache.spark.streaming.dstream.InputDStream[(String, String)] = org.apache.spark.streaming.kafka.DirectKafkaInputDStream@15d0d5f0\n"}]},"apps":[],"jobName":"paragraph_1588700200416_1098235044","id":"20190925-110033_1852097161","dateCreated":"2020-05-05T20:36:40+0300","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:22990"},{"title":"Read the Flights data from the memory grid and run our model prediction on it","text":"%spark\n\nval for_clac = spark.read.grid[FlightDelaysWithWeather].as[FlightDelaysWithWeather].where(\"prediction == 'for_calc'\")\nval cnt = for_clac.count\nprintln(\"About to update \" + cnt + \" records\")\nval flightDelayPredictions = for_clac.map{fd => \n                        val featuresVector = Array(fd.month.toDouble, fd.dayOfWeek.toDouble,\n                            (\"%04d\".format(fd.crsDepTime.toInt).take(2)).toDouble, fd.awnd.toDouble, fd.prcp.toDouble, fd.tmax.toDouble, fd.tmin.toDouble)\n                        val prediction = predictFlightDelaysRFModel.predict( Vectors.dense(featuresVector))\n                        if(prediction > 0)\n                            fd.prediction = \"Delayed\"\n                        else\n                            fd.prediction = \"OK\"\n\n                        fd\n       \n   }.rdd.saveToGrid()\nprintln(\"Updated predictions for \" + cnt + \" records done\")","user":"anonymous","dateUpdated":"2020-05-05T20:36:40+0300","config":{"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"title":true,"results":{"0":{"graph":{"mode":"table","height":300,"optionOpen":false,"setting":{"table":{"tableGridState":{},"tableColumnTypeState":{"names":{"_1":"string","_2":"string"},"updated":false},"tableOptionSpecHash":"[{\"name\":\"useFilter\",\"valueType\":\"boolean\",\"defaultValue\":false,\"widget\":\"checkbox\",\"description\":\"Enable filter for columns\"},{\"name\":\"showPagination\",\"valueType\":\"boolean\",\"defaultValue\":false,\"widget\":\"checkbox\",\"description\":\"Enable pagination for better navigation\"},{\"name\":\"showAggregationFooter\",\"valueType\":\"boolean\",\"defaultValue\":false,\"widget\":\"checkbox\",\"description\":\"Enable a footer for displaying aggregated values\"}]","tableOptionValue":{"useFilter":false,"showPagination":false,"showAggregationFooter":false},"updated":false,"initialized":false}},"commonSetting":{}}}},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"for_clac: org.apache.spark.sql.Dataset[model.v1.FlightDelaysWithWeather] = [id: string, carrier: string ... 18 more fields]\nflightDelayPredictions: Unit = ()\nUpdated predictions for 0 records\n"}]},"apps":[],"jobName":"paragraph_1588700200416_-1462637902","id":"20191023-084426_853931483","dateCreated":"2020-05-05T20:36:40+0300","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:22991"},{"title":"Look at the predictions data","text":"%insightedge_jdbc \n\nselect * from FlightDelaysWithWeather where prediction is not null limit 50\n","user":"anonymous","dateUpdated":"2020-05-05T20:36:40+0300","config":{"editorSetting":{"language":"sql","editOnDblClick":false,"completionSupport":true},"colWidth":12,"editorMode":"ace/mode/sql","fontSize":9,"title":true,"results":{"0":{"graph":{"mode":"table","height":300,"optionOpen":false,"setting":{"table":{"tableGridState":{},"tableColumnTypeState":{"names":{"awnd":"string","cancelled":"string","carrier":"string","crsDepTime":"string","date":"string","dayOfWeek":"string","dayofMonth":"string","depDelay":"string","depDelay15":"string","dest":"string","flight_number":"string","id":"string","month":"string","origin":"string","prcp":"string","prediction":"string","snow":"string","tmax":"string","tmin":"string","year":"string"},"updated":false},"tableOptionSpecHash":"[{\"name\":\"useFilter\",\"valueType\":\"boolean\",\"defaultValue\":false,\"widget\":\"checkbox\",\"description\":\"Enable filter for columns\"},{\"name\":\"showPagination\",\"valueType\":\"boolean\",\"defaultValue\":false,\"widget\":\"checkbox\",\"description\":\"Enable pagination for better navigation\"},{\"name\":\"showAggregationFooter\",\"valueType\":\"boolean\",\"defaultValue\":false,\"widget\":\"checkbox\",\"description\":\"Enable a footer for displaying aggregated values\"}]","tableOptionValue":{"useFilter":false,"showPagination":false,"showAggregationFooter":false},"updated":false,"initialized":false}},"commonSetting":{}}}},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TABLE","data":"awnd\tcancelled\tcarrier\tcrsDepTime\tdate\tdayOfWeek\tdayofMonth\tdepDelay\tdepDelay15\tdest\tflight_number\tid\tmonth\torigin\tprcp\tprediction\tsnow\ttmax\ttmin\tyear\n0\t0.0\tOO\t1730\tnull\t7.0\t27.0\t-11.0\t0.0\tONT\t5425\t2019:1.0:27.0:7.0:1730:5425\t1.0\tSFO\t23\tOK\t0\t0\t200\t2019\n0\t0.0\tOO\t755\tnull\t7.0\t27.0\t-6.0\t0.0\tSTL\t5264\t2019:1.0:27.0:7.0:755:5264\t1.0\tORD\t31\tOK\t0\t0\t-116\t2019\n0\t0.0\tOO\t1510\tnull\t7.0\t27.0\t22.0\t1.0\tBIL\t5185\t2019:1.0:27.0:7.0:1510:5185\t1.0\tDEN\t62\tOK\t0\t0\t100\t2019\n0\t0.0\tOO\t2115\tnull\t7.0\t27.0\t16.0\t1.0\tCMX\t5061\t2019:1.0:27.0:7.0:2115:5061\t1.0\tORD\t31\tOK\t0\t0\t-116\t2019\n0\t0.0\tOO\t1920\tnull\t7.0\t27.0\t-6.0\t0.0\tSLC\t4095\t2019:1.0:27.0:7.0:1920:4095\t1.0\tDEN\t62\tOK\t0\t0\t100\t2019\n0\t0.0\tOO\t1400\tnull\t3.0\t23.0\t223.0\t1.0\tCGI\t5059\t2019:1.0:23.0:3.0:1400:5059\t1.0\tORD\t44\tOK\t56\t25\t11\t2019\n0\t0.0\tOO\t1333\tnull\t3.0\t23.0\t274.0\t1.0\tJFK\t3590\t2019:1.0:23.0:3.0:1333:3590\t1.0\tORD\t44\tOK\t56\t25\t11\t2019\n0\t0.0\tOO\t2040\tnull\t3.0\t23.0\t-7.0\t0.0\tBTR\t3274\t2019:1.0:23.0:3.0:2040:3274\t1.0\tDFW\t72\tOK\t0\t0\t89\t2019\n0\t0.0\tOO\t1506\tnull\t3.0\t23.0\t64.0\t1.0\tMKE\t3119\t2019:1.0:23.0:3.0:1506:3119\t1.0\tORD\t44\tOK\t56\t25\t11\t2019\n0\t0.0\tOO\t1635\tnull\t3.0\t23.0\t-10.0\t0.0\tHOU\t3025\t2019:1.0:23.0:3.0:1635:3025\t1.0\tDFW\t72\tOK\t0\t0\t89\t2019\n0\t0.0\tOO\t1319\tnull\t3.0\t23.0\t113.0\t1.0\tGRB\t2970\t2019:1.0:23.0:3.0:1319:2970\t1.0\tORD\t44\tOK\t56\t25\t11\t2019\n0\t0.0\tOO\t740\tnull\t2.0\t22.0\t-8.0\t0.0\tBUR\t5920\t2019:1.0:22.0:2.0:740:5920\t1.0\tSFO\t17\tOK\t0\t0\t156\t2019\n1\t1.0\tOO\t1755\tnull\t2.0\t22.0\t0.0\t0.0\tDTW\t5854\t2019:1.0:22.0:2.0:1755:5854\t1.0\tORD\t42\tOK\t46\t13\t6\t2019\n0\t0.0\tOO\t1050\tnull\t2.0\t22.0\t151.0\t1.0\tBZN\t5710\t2019:1.0:22.0:2.0:1050:5710\t1.0\tSFO\t17\tOK\t0\t0\t156\t2019\n0\t0.0\tOO\t1535\tnull\t2.0\t22.0\t-6.0\t0.0\tTUS\t5678\t2019:1.0:22.0:2.0:1535:5678\t1.0\tDEN\t85\tOK\t3\t28\t-10\t2019\n0\t0.0\tOO\t1054\tnull\t2.0\t22.0\t12.0\t0.0\tABQ\t5448\t2019:1.0:22.0:2.0:1054:5448\t1.0\tSFO\t17\tOK\t0\t0\t156\t2019\n0\t0.0\tOO\t2030\tnull\t2.0\t22.0\t-1.0\t0.0\tEGE\t5432\t2019:1.0:22.0:2.0:2030:5432\t1.0\tDEN\t85\tOK\t3\t28\t-10\t2019\n0\t0.0\tOO\t1040\tnull\t2.0\t22.0\t29.0\t1.0\tIND\t5258\t2019:1.0:22.0:2.0:1040:5258\t1.0\tDEN\t85\tOK\t3\t28\t-10\t2019\n0\t0.0\tOO\t1402\tnull\t2.0\t22.0\t-3.0\t0.0\tDRO\t5224\t2019:1.0:22.0:2.0:1402:5224\t1.0\tDEN\t85\tOK\t3\t28\t-10\t2019\n0\t0.0\tOO\t945\tnull\t2.0\t22.0\t13.0\t0.0\tDFW\t5211\t2019:1.0:22.0:2.0:945:5211\t1.0\tDEN\t85\tOK\t3\t28\t-10\t2019\n0\t0.0\tOO\t1130\tnull\t2.0\t22.0\t62.0\t1.0\tLBF\t5123\t2019:1.0:22.0:2.0:1130:5123\t1.0\tDEN\t85\tOK\t3\t28\t-10\t2019\n1\t1.0\tOO\t2115\tnull\t2.0\t22.0\t0.0\t0.0\tCMX\t5061\t2019:1.0:22.0:2.0:2115:5061\t1.0\tORD\t42\tDelayed\t46\t13\t6\t2019\n1\t1.0\tOO\t1400\tnull\t2.0\t22.0\t0.0\t0.0\tMBS\t5012\t2019:1.0:22.0:2.0:1400:5012\t1.0\tORD\t42\tOK\t46\t13\t6\t2019\n1\t1.0\tOO\t1846\tnull\t2.0\t22.0\t0.0\t0.0\tSLC\t3553\t2019:1.0:22.0:2.0:1846:3553\t1.0\tORD\t42\tDelayed\t46\t13\t6\t2019\n0\t0.0\tOO\t2040\tnull\t2.0\t22.0\t-4.0\t0.0\tFSD\t3254\t2019:1.0:22.0:2.0:2040:3254\t1.0\tORD\t42\tDelayed\t46\t13\t6\t2019\n1\t1.0\tOO\t1659\tnull\t2.0\t22.0\t0.0\t0.0\tIND\t3198\t2019:1.0:22.0:2.0:1659:3198\t1.0\tORD\t42\tOK\t46\t13\t6\t2019\n1\t1.0\tOO\t1005\tnull\t2.0\t22.0\t0.0\t0.0\tFSD\t3004\t2019:1.0:22.0:2.0:1005:3004\t1.0\tORD\t42\tOK\t46\t13\t6\t2019\n0\t0.0\tOO\t603\tnull\t1.0\t21.0\t-2.0\t0.0\tSFO\t5994\t2019:1.0:21.0:1.0:603:5994\t1.0\tDFW\t68\tOK\t0\t0\t150\t2019\n0\t0.0\tOO\t1740\tnull\t1.0\t21.0\t-2.0\t0.0\tBNA\t5917\t2019:1.0:21.0:1.0:1740:5917\t1.0\tDEN\t50\tDelayed\t0\t5\t144\t2019\n0\t0.0\tOO\t2040\tnull\t1.0\t21.0\t-5.0\t0.0\tBOI\t5771\t2019:1.0:21.0:1.0:2040:5771\t1.0\tSFO\t47\tDelayed\t8\t0\t144\t2019\n0\t0.0\tOO\t1800\tnull\t1.0\t21.0\t-5.0\t0.0\tSNA\t5728\t2019:1.0:21.0:1.0:1800:5728\t1.0\tSFO\t47\tDelayed\t8\t0\t144\t2019\n0\t0.0\tOO\t640\tnull\t1.0\t21.0\t-9.0\t0.0\tSBP\t5656\t2019:1.0:21.0:1.0:640:5656\t1.0\tSFO\t47\tOK\t8\t0\t144\t2019\n0\t0.0\tOO\t900\tnull\t1.0\t21.0\t5.0\t0.0\tCHS\t5527\t2019:1.0:21.0:1.0:900:5527\t1.0\tORD\t38\tOK\t0\t3\t-82\t2019\n0\t0.0\tOO\t1620\tnull\t1.0\t21.0\t3.0\t0.0\tPDX\t5456\t2019:1.0:21.0:1.0:1620:5456\t1.0\tSFO\t47\tDelayed\t8\t0\t144\t2019\n0\t0.0\tOO\t1735\tnull\t1.0\t21.0\t15.0\t1.0\tMKE\t5436\t2019:1.0:21.0:1.0:1735:5436\t1.0\tDEN\t50\tDelayed\t0\t5\t144\t2019\n0\t0.0\tOO\t600\tnull\t1.0\t21.0\t-3.0\t0.0\tLAX\t5374\t2019:1.0:21.0:1.0:600:5374\t1.0\tSFO\t47\tOK\t8\t0\t144\t2019\n0\t0.0\tOO\t1550\tnull\t1.0\t21.0\t-3.0\t0.0\tSLC\t5231\t2019:1.0:21.0:1.0:1550:5231\t1.0\tDEN\t50\tDelayed\t0\t5\t144\t2019\n0\t0.0\tOO\t1900\tnull\t1.0\t21.0\t-6.0\t0.0\tEUG\t5212\t2019:1.0:21.0:1.0:1900:5212\t1.0\tDEN\t50\tDelayed\t0\t5\t144\t2019\n0\t0.0\tOO\t1400\tnull\t1.0\t21.0\t63.0\t1.0\tAVL\t5136\t2019:1.0:21.0:1.0:1400:5136\t1.0\tORD\t38\tDelayed\t0\t3\t-82\t2019\n0\t0.0\tOO\t2115\tnull\t1.0\t21.0\t-2.0\t0.0\tPAH\t5070\t2019:1.0:21.0:1.0:2115:5070\t1.0\tORD\t38\tDelayed\t0\t3\t-82\t2019\n0\t0.0\tOO\t1333\tnull\t1.0\t21.0\t1.0\t0.0\tJFK\t3590\t2019:1.0:21.0:1.0:1333:3590\t1.0\tORD\t38\tDelayed\t0\t3\t-82\t2019\n0\t0.0\tOO\t955\tnull\t1.0\t21.0\t-4.0\t0.0\tOMA\t3260\t2019:1.0:21.0:1.0:955:3260\t1.0\tORD\t38\tOK\t0\t3\t-82\t2019\n0\t0.0\tOO\t1010\tnull\t1.0\t21.0\t116.0\t1.0\tOKC\t3192\t2019:1.0:21.0:1.0:1010:3192\t1.0\tORD\t38\tDelayed\t0\t3\t-82\t2019\n0\t0.0\tOO\t1030\tnull\t1.0\t21.0\t-4.0\t0.0\tMHK\t3026\t2019:1.0:21.0:1.0:1030:3026\t1.0\tDFW\t68\tDelayed\t0\t0\t150\t2019\n0\t0.0\tOO\t2036\tnull\t1.0\t21.0\t-3.0\t0.0\tBNA\t2972\t2019:1.0:21.0:1.0:2036:2972\t1.0\tORD\t38\tDelayed\t0\t3\t-82\t2019\n0\t0.0\tOO\t1740\tnull\t7.0\t20.0\t10.0\t0.0\tBNA\t5917\t2019:1.0:20.0:7.0:1740:5917\t1.0\tDEN\t50\tOK\t0\t0\t128\t2019\n0\t0.0\tOO\t806\tnull\t7.0\t20.0\t-5.0\t0.0\tPIT\t5790\t2019:1.0:20.0:7.0:806:5790\t1.0\tORD\t60\tOK\t0\t0\t-99\t2019\n0\t0.0\tOO\t1930\tnull\t7.0\t20.0\t85.0\t1.0\tBOI\t5691\t2019:1.0:20.0:7.0:1930:5691\t1.0\tORD\t60\tDelayed\t0\t0\t-99\t2019\n0\t0.0\tOO\t740\tnull\t7.0\t20.0\t70.0\t1.0\tMDT\t5548\t2019:1.0:20.0:7.0:740:5548\t1.0\tORD\t60\tOK\t0\t0\t-99\t2019\n0\t0.0\tOO\t1930\tnull\t7.0\t20.0\t-6.0\t0.0\tSFO\t5483\t2019:1.0:20.0:7.0:1930:5483\t1.0\tDFW\t31\tOK\t0\t0\t83\t2019\n"}]},"apps":[],"jobName":"paragraph_1588700200416_-453838717","id":"20191023-122601_348040933","dateCreated":"2020-05-05T20:36:40+0300","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:22992"},{"text":"%insightedge_jdbc\nselect prediction, count(*) as \"count\" from FlightDelaysWithWeather group by prediction\n","user":"anonymous","dateUpdated":"2020-05-05T20:36:40+0300","config":{"editorSetting":{"language":"sql","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/sql","fontSize":9,"title":false,"results":{"0":{"graph":{"mode":"pieChart","height":300,"optionOpen":false,"setting":{"table":{"tableGridState":{},"tableColumnTypeState":{"names":{"prediction":"string","count":"string"},"updated":false},"tableOptionSpecHash":"[{\"name\":\"useFilter\",\"valueType\":\"boolean\",\"defaultValue\":false,\"widget\":\"checkbox\",\"description\":\"Enable filter for columns\"},{\"name\":\"showPagination\",\"valueType\":\"boolean\",\"defaultValue\":false,\"widget\":\"checkbox\",\"description\":\"Enable pagination for better navigation\"},{\"name\":\"showAggregationFooter\",\"valueType\":\"boolean\",\"defaultValue\":false,\"widget\":\"checkbox\",\"description\":\"Enable a footer for displaying aggregated values\"}]","tableOptionValue":{"useFilter":false,"showPagination":false,"showAggregationFooter":false},"updated":false,"initialized":false}},"commonSetting":{}},"helium":{}}},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TABLE","data":"prediction\tcount\nDelayed\t844\nOK\t1626\n"}]},"apps":[],"jobName":"paragraph_1588700200417_-1558719962","id":"20191023-123209_886208345","dateCreated":"2020-05-05T20:36:40+0300","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:22993"},{"text":"%insightedge_jdbc\n","user":"anonymous","dateUpdated":"2020-05-05T20:36:40+0300","config":{"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1588700200417_649944429","id":"20200503-103136_797190294","dateCreated":"2020-05-05T20:36:40+0300","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:22994"}],"name":"Gigaspaces Studio/2.Flight Delays 2","id":"2F79Q2EZK","noteParams":{},"noteForms":{},"angularObjects":{"md:shared_process":[],"sh:shared_process":[],"insightedge_jdbc:shared_process":[],"spark:shared_process":[]},"config":{"isZeppelinNotebookCronEnable":false,"looknfeel":"default","personalizedMode":"false"},"info":{}}